{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# VSA Models Comparison Guide\n\nTopics: MAP, FHRR, HRR, BSC model selection and characteristics\nTime: 15 minutes\nPrerequisites: 00_quickstart.py, 01_basic_operations.py\nRelated: 40_model_hrr_correlation.py, 41_model_ghrr_diagonality.py, 42_model_bsdc_seg.py\n\nThis example helps you choose the right VSA model for your application by\ndemonstrating the key differences, trade-offs, and use cases for each model\nin the HoloVec library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from holovec import VSA\n\nprint(\"=\" * 70)\nprint(\"VSA Models Comparison - Choosing the Right Model\")\nprint(\"=\" * 70)\nprint()\n\n# ============================================================================\n# Overview: Available Models\n# ============================================================================\nprint(\"Available VSA Models in HoloVec\")\nprint(\"-\" * 70)\nprint()\nprint(\"1. MAP  (Multiply-Add-Permute)\")\nprint(\"   - Element-wise operations, self-inverse binding\")\nprint(\"   - Fast, simple, works on CPU\")\nprint()\nprint(\"2. FHRR (Fourier Holographic Reduced Representations)\")\nprint(\"   - Complex-valued, exact inverses\")\nprint(\"   - Best capacity, recommended for most applications\")\nprint()\nprint(\"3. HRR  (Holographic Reduced Representations)\")\nprint(\"   - Real-valued circular convolution\")\nprint(\"   - Classic model, good for research reproduction\")\nprint()\nprint(\"4. BSC  (Binary Spatter Codes)\")\nprint(\"   - Binary vectors with XOR binding\")\nprint(\"   - Memory-efficient, exact inverse\")\nprint()\nprint(\"5. BSDC (Binary Sparse Distributed Codes)\")\nprint(\"   - Sparse binary representation\")\nprint(\"   - Inspired by neuroscience, brain-like sparsity\")\nprint()\n\n# ============================================================================\n# Comparison 1: Model Characteristics\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Comparison 1: Model Characteristics\")\nprint(\"=\" * 70)\nprint()\n\nmodels_info = {}\n\n# Create each model\nfor model_name in ['MAP', 'FHRR', 'HRR', 'BSC']:\n    model = VSA.create(model_name, dim=10000, seed=42)\n    models_info[model_name] = {\n        'model': model,\n        'self_inverse': model.is_self_inverse,\n        'commutative': model.is_commutative,\n        'exact_inverse': model.is_exact_inverse,\n        'space': model.space.space_name\n    }\n\n# Print comparison table\nprint(f\"{'Model':<8} {'Space':<12} {'Self-Inv':<10} {'Commut':<10} {'Exact-Inv':<10}\")\nprint(\"-\" * 70)\nfor name, info in models_info.items():\n    print(f\"{name:<8} {info['space']:<12} {str(info['self_inverse']):<10} \"\n          f\"{str(info['commutative']):<10} {str(info['exact_inverse']):<10}\")\nprint()\n\nprint(\"Key:\")\nprint(\"  Self-Inverse: bind(A, B) can be unbound without separate inverse\")\nprint(\"  Commutative: bind(A, B) = bind(B, A)\")\nprint(\"  Exact-Inverse: Unbinding recovers exact original (no approximation)\")\nprint()\n\n# ============================================================================\n# Comparison 2: Capacity (Bundling Performance)\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Comparison 2: Bundling Capacity\")\nprint(\"=\" * 70)\nprint()\nprint(\"Testing: How many random vectors can be bundled before similarity degrades?\")\nprint()\n\n# Test bundling capacity for each model\nfor model_name in ['FHRR', 'MAP', 'HRR']:\n    model = models_info[model_name]['model']\n\n    # Create a target vector and bundle it with noise\n    target = model.random(seed=100)\n    n_items_list = [1, 5, 10, 20, 50]\n\n    print(f\"{model_name} Bundling:\")\n    for n in n_items_list:\n        # Bundle target with (n-1) random vectors\n        vectors = [target] + [model.random(seed=100+i) for i in range(1, n)]\n        bundled = model.bundle(vectors)\n\n        # Measure similarity to target\n        similarity = float(model.similarity(bundled, target))\n        print(f\"  {n:3d} items bundled: similarity = {similarity:.3f}\")\n    print()\n\nprint(\"Observation:\")\nprint(\"  - FHRR maintains highest similarity (best capacity)\")\nprint(\"  - MAP and HRR degrade faster with more items\")\nprint(\"  - For >20 bundled items, prefer FHRR\")\nprint()\n\n# ============================================================================\n# Comparison 3: Binding/Unbinding Accuracy\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Comparison 3: Binding/Unbinding Accuracy\")\nprint(\"=\" * 70)\nprint()\nprint(\"Testing: Can we accurately recover bound information?\")\nprint()\n\nfor model_name in ['FHRR', 'MAP', 'HRR']:\n    model = models_info[model_name]['model']\n\n    # Create vectors\n    a = model.random(seed=1)\n    b = model.random(seed=2)\n\n    # Bind\n    c = model.bind(a, b)\n\n    # Unbind to recover b\n    b_recovered = model.unbind(c, a)\n\n    # Measure recovery accuracy\n    similarity = float(model.similarity(b, b_recovered))\n\n    print(f\"{model_name}: bind(A, B) then unbind(\u00b7, A) \u2192 similarity = {similarity:.4f}\")\n\nprint()\nprint(\"Observation:\")\nprint(\"  - FHRR: Exact inverse (similarity \u2248 1.000)\")\nprint(\"  - MAP: Approximate but very good (similarity \u2248 0.999)\")\nprint(\"  - HRR: Good approximation (similarity \u2248 0.990)\")\nprint()\n\n# ============================================================================\n# Comparison 4: Performance Characteristics\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Comparison 4: Performance Characteristics\")\nprint(\"=\" * 70)\nprint()\n\nimport time\n\n# Time binding operations\nn_iterations = 1000\nresults = {}\n\nfor model_name in ['MAP', 'FHRR', 'HRR']:\n    model = models_info[model_name]['model']\n    a = model.random(seed=1)\n    b = model.random(seed=2)\n\n    # Time binding\n    start = time.time()\n    for _ in range(n_iterations):\n        _ = model.bind(a, b)\n    elapsed = time.time() - start\n\n    results[model_name] = elapsed\n\n# Normalize to MAP\nmap_time = results['MAP']\nprint(f\"Binding Speed (relative to MAP, {n_iterations} operations):\")\nprint(f\"  MAP:  1.00x (fastest - element-wise multiply)\")\nprint(f\"  FHRR: {results['FHRR']/map_time:.2f}x (complex FFT operations)\")\nprint(f\"  HRR:  {results['HRR']/map_time:.2f}x (circular convolution via FFT)\")\nprint()\nprint(\"Note: Times may vary by backend (NumPy vs PyTorch vs JAX)\")\nprint()\n\n# ============================================================================\n# Decision Guide: When to Use Each Model\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Decision Guide: When to Use Each Model\")\nprint(\"=\" * 70)\nprint()\n\nprint(\"\ud83c\udfc6 FHRR - **Recommended for most applications**\")\nprint(\"   Use when:\")\nprint(\"   - You need high capacity (bundling many items)\")\nprint(\"   - Exact inverse is important\")\nprint(\"   - Working with continuous encoders (FractionalPowerEncoder)\")\nprint(\"   - Moderate performance is acceptable\")\nprint()\n\nprint(\"\u26a1 MAP - **Best for speed-critical applications**\")\nprint(\"   Use when:\")\nprint(\"   - Performance is critical (real-time systems)\")\nprint(\"   - Self-inverse binding is beneficial\")\nprint(\"   - Simple element-wise operations preferred\")\nprint(\"   - Lower capacity is acceptable\")\nprint()\n\nprint(\"\ud83d\udcda HRR - **Good for research and reproduction**\")\nprint(\"   Use when:\")\nprint(\"   - Reproducing classic HDC papers\")\nprint(\"   - Real-valued representations required\")\nprint(\"   - Good balance of capacity and performance\")\nprint()\n\nprint(\"\ud83d\udcbe BSC - **Binary and memory-efficient**\")\nprint(\"   Use when:\")\nprint(\"   - Memory is extremely limited\")\nprint(\"   - Binary operations preferred\")\nprint(\"   - Exact XOR-based inverse needed\")\nprint()\n\nprint(\"\ud83e\udde0 BSDC - **Brain-inspired sparse coding**\")\nprint(\"   Use when:\")\nprint(\"   - Biological plausibility important\")\nprint(\"   - Sparse representations desired\")\nprint(\"   - Neuromorphic hardware targeted\")\nprint()\n\n# ============================================================================\n# Example: Same Application, Different Models\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Example: Temperature Encoding with Different Models\")\nprint(\"=\" * 70)\nprint()\n\nfrom holovec.encoders import FractionalPowerEncoder, ThermometerEncoder\n\n# Encode same data with different models\ntemps = [20.0, 21.0, 40.0]\n\n# FPE works with FHRR and HRR\nprint(\"Using FractionalPowerEncoder (works with FHRR, HRR):\")\nfor model_name in ['FHRR', 'HRR']:\n    model = models_info[model_name]['model']\n    encoder = FractionalPowerEncoder(model, min_val=0, max_val=100, bandwidth=0.1)\n\n    hvs = [encoder.encode(t) for t in temps]\n\n    # Check similarity between similar temps (20\u00b0C vs 21\u00b0C)\n    sim_close = float(model.similarity(hvs[0], hvs[1]))\n\n    # Check similarity between distant temps (20\u00b0C vs 40\u00b0C)\n    sim_far = float(model.similarity(hvs[0], hvs[2]))\n\n    print(f\"  {model_name}: sim(20\u00b0C, 21\u00b0C)={sim_close:.3f}, sim(20\u00b0C, 40\u00b0C)={sim_far:.3f}\")\n\nprint()\n\n# ThermometerEncoder works with all models\nprint(\"Using ThermometerEncoder (works with all models):\")\nfor model_name in ['FHRR', 'MAP', 'HRR', 'BSC']:\n    model = models_info[model_name]['model']\n    encoder = ThermometerEncoder(model, min_val=0, max_val=100, n_bins=100)\n\n    hvs = [encoder.encode(t) for t in temps]\n\n    # Check similarity between similar temps (20\u00b0C vs 21\u00b0C)\n    sim_close = float(model.similarity(hvs[0], hvs[1]))\n\n    # Check similarity between distant temps (20\u00b0C vs 40\u00b0C)\n    sim_far = float(model.similarity(hvs[0], hvs[2]))\n\n    print(f\"  {model_name}: sim(20\u00b0C, 21\u00b0C)={sim_close:.3f}, sim(20\u00b0C, 40\u00b0C)={sim_far:.3f}\")\n\nprint()\nprint(\"Observation:\")\nprint(\"  - All models preserve similarity structure\")\nprint(\"  - Different encoders may have model compatibility constraints\")\nprint(\"  - Check encoder.compatible_models before use\")\nprint()\n\n# ============================================================================\n# Summary\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Summary: Quick Reference\")\nprint(\"=\" * 70)\nprint()\nprint(\"Model Selection Flowchart:\")\nprint()\nprint(\"  Need exact inverses? \u2192 Use FHRR\")\nprint(\"  Need maximum speed? \u2192 Use MAP\")\nprint(\"  Reproducing research? \u2192 Use HRR\")\nprint(\"  Need binary/sparse? \u2192 Use BSC or BSDC\")\nprint()\nprint(\"  **Default recommendation: FHRR**\")\nprint(\"  (Best balance of capacity, accuracy, and features)\")\nprint()\nprint(\"Next steps:\")\nprint(\"  \u2192 Try different models with your specific use case\")\nprint(\"  \u2192 See model-specific examples: 40-42_model_*.py\")\nprint(\"  \u2192 Explore encoders with your chosen model: 10-18_encoders_*.py\")\nprint()\nprint(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}