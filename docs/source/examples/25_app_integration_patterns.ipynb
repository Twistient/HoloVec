{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Integration Patterns and Multimodal Fusion\n\nTopics: Multimodal fusion, encoder integration, design patterns, hierarchical encoding\nTime: 25 minutes\nPrerequisites: 10_encoders_scalar.py, 14_encoders_ngram.py, 23_app_symbolic_reasoning.py\nRelated: 20-22_app_*.py (domain-specific applications)\n\nThis example demonstrates integration patterns for building complex hyperdimensional\ncomputing systems. Learn how to combine multiple encoders, fuse multimodal data,\nand structure hierarchical representations for real-world applications.\n\nKey concepts:\n- Multimodal fusion: Combining text, images, and numeric data\n- Encoder composition: Integrate scalar, sequence, spatial encoders\n- Hierarchical encoding: Build layered representations\n- Design patterns: Reusable structures for HDC systems\n- End-to-end workflow: From raw data to query answering\n\nThis capstone example shows how the individual encoders and techniques\nwork together to build sophisticated AI systems.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom holovec import VSA\nfrom holovec.encoders import (\n    FractionalPowerEncoder,\n    NGramEncoder,\n    VectorEncoder,\n    PositionBindingEncoder,\n)\nfrom holovec.retrieval import ItemStore\n\nprint(\"=\" * 70)\nprint(\"Integration Patterns and Multimodal Fusion\")\nprint(\"=\" * 70)\nprint()\n\n# Create model\nmodel = VSA.create('FHRR', dim=10000, seed=42)\n\n# ============================================================================\n# Pattern 1: Multimodal Fusion - Combining Different Data Types\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Pattern 1: Multimodal Fusion - Product Reviews\")\nprint(\"=\" * 70)\n\nprint(\"\\nScenario: Encode product reviews with text + rating + price\")\n\n# Setup encoders for different modalities\nprint(\"\\n  Setting up encoders:\")\n\n# Text modality: N-gram encoder\ntext_encoder = NGramEncoder(model, n=3, seed=42)\nprint(\"    - Text: NGramEncoder (3-grams)\")\n\n# Rating modality: Scalar encoder (1-5 stars)\nrating_encoder = FractionalPowerEncoder(model, min_val=1, max_val=5, bandwidth=0.2, seed=43)\nprint(\"    - Rating: FractionalPowerEncoder (1-5 stars)\")\n\n# Price modality: Scalar encoder ($0-$1000)\nprice_encoder = FractionalPowerEncoder(model, min_val=0, max_val=1000, bandwidth=20, seed=44)\nprint(\"    - Price: FractionalPowerEncoder ($0-$1000)\")\n\n# Define modality dimension vectors\nTEXT_DIM = model.random(seed=100)\nRATING_DIM = model.random(seed=101)\nPRICE_DIM = model.random(seed=102)\n\nprint(\"\\n  Modality dimensions: TEXT, RATING, PRICE\")\n\n# Encode example product reviews\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Encoding 3 product reviews:\")\nprint(\"=\" * 70)\n\nreviews = [\n    {\n        \"id\": \"product_A\",\n        \"text\": \"excellent quality fast shipping\",\n        \"rating\": 5.0,\n        \"price\": 49.99\n    },\n    {\n        \"id\": \"product_B\",\n        \"text\": \"poor quality slow shipping\",\n        \"rating\": 2.0,\n        \"price\": 39.99\n    },\n    {\n        \"id\": \"product_C\",\n        \"text\": \"excellent product fast delivery\",\n        \"rating\": 4.5,\n        \"price\": 89.99\n    }\n]\n\nencoded_reviews = {}\n\nfor review in reviews:\n    print(f\"\\n  {review['id']}:\")\n    print(f\"    Text: '{review['text']}'\")\n    print(f\"    Rating: {review['rating']}/5, Price: ${review['price']}\")\n\n    # Encode each modality\n    text_hv = text_encoder.encode(review[\"text\"])\n    rating_hv = rating_encoder.encode(review[\"rating\"])\n    price_hv = price_encoder.encode(review[\"price\"])\n\n    # Bind each modality to its dimension vector\n    text_bound = model.bind(TEXT_DIM, text_hv)\n    rating_bound = model.bind(RATING_DIM, rating_hv)\n    price_bound = model.bind(PRICE_DIM, price_hv)\n\n    # Bundle all modalities into single multimodal representation\n    multimodal_hv = model.bundle([text_bound, rating_bound, price_bound])\n    encoded_reviews[review[\"id\"]] = multimodal_hv\n\n    print(f\"    \u2192 Multimodal HV shape: {multimodal_hv.shape}\")\n\n# Query: Find products similar to \"excellent fast shipping, 5 stars, ~$50\"\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Query: Products like 'excellent fast', 5 stars, $50\")\nprint(\"=\" * 70)\n\nquery_text = \"excellent fast\"\nquery_rating = 5.0\nquery_price = 50.0\n\n# Encode query\nquery_text_hv = text_encoder.encode(query_text)\nquery_rating_hv = rating_encoder.encode(query_rating)\nquery_price_hv = price_encoder.encode(query_price)\n\n# Bind to dimensions\nquery_text_bound = model.bind(TEXT_DIM, query_text_hv)\nquery_rating_bound = model.bind(RATING_DIM, query_rating_hv)\nquery_price_bound = model.bind(PRICE_DIM, query_price_hv)\n\n# Bundle query modalities\nquery_hv = model.bundle([query_text_bound, query_rating_bound, query_price_bound])\n\nprint(\"\\nSimilarity to products:\")\nfor prod_id, prod_hv in encoded_reviews.items():\n    sim = float(model.similarity(query_hv, prod_hv))\n    print(f\"  {prod_id}: {sim:.3f}\")\n\nprint(\"\\nKey observation:\")\nprint(\"  - Product A ranks highest (excellent/fast + 5 stars + $49.99)\")\nprint(\"  - Multimodal fusion combines complementary information\")\nprint(\"  - Each modality contributes to overall similarity\")\n\n# ============================================================================\n# Pattern 2: Hierarchical Encoding - Part-Whole Relationships\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Pattern 2: Hierarchical Encoding - Document Structure\")\nprint(\"=\" * 70)\n\nprint(\"\\nScenario: Encode document with sections and paragraphs\")\n\n# Define hierarchy levels\nDOCUMENT = model.random(seed=200)\nSECTION = model.random(seed=201)\nPARAGRAPH = model.random(seed=202)\n\nprint(\"  Hierarchy: DOCUMENT \u2192 SECTION \u2192 PARAGRAPH\")\n\n# Encode document structure\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Document: 'Machine Learning Tutorial'\")\nprint(\"=\" * 70)\n\n# Section 1: Introduction\nintro_para1 = \"machine learning algorithms process data\"\nintro_para2 = \"supervised learning uses labeled data\"\n\nintro_p1_hv = text_encoder.encode(intro_para1)\nintro_p2_hv = text_encoder.encode(intro_para2)\n\nintro_section = model.bundle([\n    model.bind(PARAGRAPH, intro_p1_hv),\n    model.bind(PARAGRAPH, intro_p2_hv)\n])\n\nprint(\"\\n  Section 1 (Introduction):\")\nprint(f\"    Para 1: '{intro_para1}'\")\nprint(f\"    Para 2: '{intro_para2}'\")\n\n# Section 2: Methods\nmethods_para1 = \"neural networks learn patterns from data\"\nmethods_para2 = \"decision trees create classification rules\"\n\nmethods_p1_hv = text_encoder.encode(methods_para1)\nmethods_p2_hv = text_encoder.encode(methods_para2)\n\nmethods_section = model.bundle([\n    model.bind(PARAGRAPH, methods_p1_hv),\n    model.bind(PARAGRAPH, methods_p2_hv)\n])\n\nprint(\"\\n  Section 2 (Methods):\")\nprint(f\"    Para 1: '{methods_para1}'\")\nprint(f\"    Para 2: '{methods_para2}'\")\n\n# Combine sections into document\ndocument_hv = model.bundle([\n    model.bind(SECTION, intro_section),\n    model.bind(SECTION, methods_section)\n])\n\nprint(\"\\n  \u2192 Document HV (hierarchical encoding)\")\n\n# Query: Which section discusses \"neural networks\"?\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Query: Which section discusses 'neural networks'?\")\nprint(\"=\" * 70)\n\nquery_nn = text_encoder.encode(\"neural networks\")\n\n# Check similarity to each section\nsim_intro = float(model.similarity(intro_section, model.bind(PARAGRAPH, query_nn)))\nsim_methods = float(model.similarity(methods_section, model.bind(PARAGRAPH, query_nn)))\n\nprint(f\"\\n  Intro section:   {sim_intro:.3f}\")\nprint(f\"  Methods section: {sim_methods:.3f}  \u2190 Best match!\")\n\nprint(\"\\nKey observation:\")\nprint(\"  - Hierarchical structure preserves part-whole relationships\")\nprint(\"  - Can query at different levels (document, section, paragraph)\")\nprint(\"  - Enables structured document retrieval\")\n\n# ============================================================================\n# Pattern 3: Encoder Composition - Building Complex Encoders\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Pattern 3: Encoder Composition - Feature Vectors with Labels\")\nprint(\"=\" * 70)\n\nprint(\"\\nScenario: Encode labeled feature vectors (supervised learning)\")\n\n# Setup: Vector encoder for features + position encoder for class label\nfeature_dim = 5\nfeature_encoder = VectorEncoder(\n    model,\n    FractionalPowerEncoder(model, min_val=0, max_val=1, seed=45),\n    n_dimensions=feature_dim,\n    seed=46\n)\n\nlabel_encoder = PositionBindingEncoder(model, seed=47)\n\nprint(f\"  Features: VectorEncoder ({feature_dim}D)\")\nprint(\"  Labels: PositionBindingEncoder\")\n\n# Define label and feature dimensions\nFEATURES = model.random(seed=300)\nLABEL = model.random(seed=301)\n\n# Encode training examples\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Encoding training examples:\")\nprint(\"=\" * 70)\n\ntraining_data = [\n    {\"features\": np.array([0.8, 0.9, 0.1, 0.2, 0.1]), \"label\": [\"class_A\"]},\n    {\"features\": np.array([0.2, 0.1, 0.9, 0.8, 0.9]), \"label\": [\"class_B\"]},\n    {\"features\": np.array([0.7, 0.8, 0.2, 0.3, 0.2]), \"label\": [\"class_A\"]},\n]\n\nencoded_examples = []\n\nfor i, example in enumerate(training_data):\n    print(f\"\\n  Example {i+1}:\")\n    print(f\"    Features: {example['features']}\")\n    print(f\"    Label: {example['label'][0]}\")\n\n    # Encode features and label\n    features_hv = feature_encoder.encode(example[\"features\"])\n    label_hv = label_encoder.encode(example[\"label\"])\n\n    # Bind to dimensions\n    features_bound = model.bind(FEATURES, features_hv)\n    label_bound = model.bind(LABEL, label_hv)\n\n    # Bundle into example representation\n    example_hv = model.bundle([features_bound, label_bound])\n    encoded_examples.append(example_hv)\n\n# Create training memory\ntraining_memory = model.bundle(encoded_examples)\nprint(\"\\n  \u2192 Training memory (bundled all examples)\")\n\n# Query: Predict label for new features\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Prediction: Classify new features\")\nprint(\"=\" * 70)\n\ntest_features = np.array([0.85, 0.90, 0.15, 0.25, 0.15])\nprint(f\"\\n  Test features: {test_features}\")\n\n# Encode test features\ntest_features_hv = feature_encoder.encode(test_features)\ntest_features_bound = model.bind(FEATURES, test_features_hv)\n\n# Query training memory for similar examples\nprint(\"\\n  Similarity to training examples:\")\nfor i, ex_hv in enumerate(encoded_examples):\n    sim = float(model.similarity(test_features_bound, ex_hv))\n    label = training_data[i][\"label\"][0]\n    print(f\"    Example {i+1} ({label}): {sim:.3f}\")\n\n# Extract label from most similar example\nquery_label = model.unbind(encoded_examples[0], FEATURES)  # Most similar to example 1\nsim_a = float(model.similarity(query_label, label_encoder.encode([\"class_A\"])))\nsim_b = float(model.similarity(query_label, label_encoder.encode([\"class_B\"])))\n\nprint(f\"\\n  Predicted label probabilities:\")\nprint(f\"    class_A: {sim_a:.3f}  \u2190 Prediction\")\nprint(f\"    class_B: {sim_b:.3f}\")\n\nprint(\"\\nKey observation:\")\nprint(\"  - Composition combines multiple encoders\")\nprint(\"  - Enables flexible, structured data encoding\")\nprint(\"  - Supports supervised learning paradigms\")\n\n# ============================================================================\n# Pattern 4: Semantic Binding - Context-Dependent Representations\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Pattern 4: Semantic Binding - Word Sense Disambiguation\")\nprint(\"=\" * 70)\n\nprint(\"\\nScenario: Encode words with context to disambiguate meaning\")\n\n# Setup: Encode word + context\nWORD = model.random(seed=400)\nCONTEXT = model.random(seed=401)\n\n# Encode \"bank\" in different contexts\nbank = model.random(seed=500)\n\ncontext1 = text_encoder.encode(\"river water shore\")\ncontext2 = text_encoder.encode(\"money deposit account\")\n\nprint(\"\\n  Word: 'bank'\")\nprint(\"  Context 1: 'river water shore' (riverbank)\")\nprint(\"  Context 2: 'money deposit account' (financial bank)\")\n\n# Create context-dependent representations\nbank_river = model.bundle([\n    model.bind(WORD, bank),\n    model.bind(CONTEXT, context1)\n])\n\nbank_financial = model.bundle([\n    model.bind(WORD, bank),\n    model.bind(CONTEXT, context2)\n])\n\nprint(\"\\n  \u2192 bank_river (riverbank sense)\")\nprint(\"  \u2192 bank_financial (financial sense)\")\n\n# Test: Which sense matches new context?\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Test: 'bank' in context 'deposit money account'\")\nprint(\"=\" * 70)\n\ntest_context = text_encoder.encode(\"deposit money account\")\ntest_bank = model.bundle([\n    model.bind(WORD, bank),\n    model.bind(CONTEXT, test_context)\n])\n\nsim_river = float(model.similarity(test_bank, bank_river))\nsim_financial = float(model.similarity(test_bank, bank_financial))\n\nprint(f\"\\n  Similarity to riverbank sense:   {sim_river:.3f}\")\nprint(f\"  Similarity to financial sense:   {sim_financial:.3f}  \u2190 Best match!\")\n\nprint(\"\\nKey observation:\")\nprint(\"  - Context binding creates distinct word senses\")\nprint(\"  - Disambiguates polysemous words automatically\")\nprint(\"  - Models compositional semantics\")\n\n# ============================================================================\n# Pattern 5: End-to-End Application - Multimodal Search Engine\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Pattern 5: End-to-End Multimodal Search Engine\")\nprint(\"=\" * 70)\n\nprint(\"\\nScenario: Search products by text description + price range\")\n\n# Build product database\nproduct_store = ItemStore(model)\n\nproducts = [\n    {\"id\": \"laptop_premium\", \"desc\": \"high performance laptop fast processor\", \"price\": 1200},\n    {\"id\": \"laptop_budget\", \"desc\": \"affordable laptop basic performance\", \"price\": 400},\n    {\"id\": \"phone_premium\", \"desc\": \"smartphone fast processor excellent camera\", \"price\": 900},\n    {\"id\": \"phone_budget\", \"desc\": \"basic phone affordable price\", \"price\": 200},\n]\n\nprint(\"\\n  Building product database:\")\n\nfor prod in products:\n    desc_hv = text_encoder.encode(prod[\"desc\"])\n    price_hv = price_encoder.encode(float(prod[\"price\"]))\n\n    prod_hv = model.bundle([\n        model.bind(TEXT_DIM, desc_hv),\n        model.bind(PRICE_DIM, price_hv)\n    ])\n\n    product_store.add(prod[\"id\"], prod_hv)\n    print(f\"    {prod['id']}: '{prod['desc']}' (${prod['price']})\")\n\n# Query: \"fast laptop under $500\"\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Query: 'fast laptop' under $500\")\nprint(\"=\" * 70)\n\nquery_desc = \"fast laptop\"\nquery_max_price = 500\n\nquery_desc_hv = text_encoder.encode(query_desc)\nquery_price_hv = price_encoder.encode(float(query_max_price))\n\nquery_multimodal = model.bundle([\n    model.bind(TEXT_DIM, query_desc_hv),\n    model.bind(PRICE_DIM, query_price_hv)\n])\n\n# Search product database\nresults = product_store.query(query_multimodal, k=4)\n\nprint(\"\\n  Search results (ranked by relevance):\")\nfor i, (prod_id, sim) in enumerate(results, 1):\n    # Find product details\n    prod = next(p for p in products if p[\"id\"] == prod_id)\n    print(f\"    {i}. {prod_id}: {sim:.3f}\")\n    print(f\"       Description: '{prod['desc']}'\")\n    print(f\"       Price: ${prod['price']}\")\n\nprint(\"\\nKey observation:\")\nprint(\"  - End-to-end workflow: data \u2192 encoding \u2192 retrieval\")\nprint(\"  - Multimodal query combines text and price constraints\")\nprint(\"  - ItemStore enables efficient similarity search\")\n\n# ============================================================================\n# Summary\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Summary: Integration Patterns Key Takeaways\")\nprint(\"=\" * 70)\nprint()\nprint(\"\u2713 Multimodal fusion: Combine text, numeric, and other data types\")\nprint(\"\u2713 Hierarchical encoding: Build layered, structured representations\")\nprint(\"\u2713 Encoder composition: Integrate multiple encoders flexibly\")\nprint(\"\u2713 Semantic binding: Context-dependent representations\")\nprint(\"\u2713 End-to-end systems: Complete application workflows\")\nprint()\nprint(\"Integration pattern recipes:\")\nprint()\nprint(\"1. Multimodal Fusion:\")\nprint(\"   - Encode each modality separately\")\nprint(\"   - Bind each to unique dimension vector\")\nprint(\"   - Bundle all modalities into single HV\")\nprint(\"   - Query: bundle query modalities same way\")\nprint()\nprint(\"2. Hierarchical Encoding:\")\nprint(\"   - Define level dimension vectors (document, section, paragraph)\")\nprint(\"   - Encode bottom-up: leaf \u2192 intermediate \u2192 root\")\nprint(\"   - Bind each level's content to its dimension\")\nprint(\"   - Bundle across levels for complete structure\")\nprint()\nprint(\"3. Encoder Composition:\")\nprint(\"   - Combine encoders for complex data (features + labels)\")\nprint(\"   - Use consistent dimension binding pattern\")\nprint(\"   - Enable flexible, reusable encoding pipelines\")\nprint()\nprint(\"4. Context Binding:\")\nprint(\"   - Bind primary concept to WORD dimension\")\nprint(\"   - Bind context to CONTEXT dimension\")\nprint(\"   - Bundle for context-dependent representation\")\nprint(\"   - Enables disambiguation and semantic composition\")\nprint()\nprint(\"Design principles:\")\nprint(\"  - Modularity: Combine encoders like building blocks\")\nprint(\"  - Consistency: Use same bind/bundle patterns\")\nprint(\"  - Flexibility: Adapt patterns to your domain\")\nprint(\"  - Scalability: Patterns work for any data scale\")\nprint()\nprint(\"Applications:\")\nprint(\"  - Multimodal search: Text + image + metadata\")\nprint(\"  - Document understanding: Hierarchical structure\")\nprint(\"  - Recommendation systems: User preferences + item features\")\nprint(\"  - Semantic search: Context-aware retrieval\")\nprint()\nprint(\"Next steps:\")\nprint(\"  \u2192 Apply patterns to your domain\")\nprint(\"  \u2192 Combine with cleanup strategies (27, 28)\")\nprint(\"  \u2192 Build domain-specific applications (20-22)\")\nprint()\nprint(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}