{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# HoloVec Quickstart Guide\n\nTopics: Installation, basic workflow, encoding, binding, retrieval\nTime: 5 minutes\nPrerequisites: None\nRelated: 01_basic_operations.py, 02_models_comparison.py\n\nThis quickstart demonstrates the core HoloVec workflow in under 100 lines.\nYou'll encode data, compose representations, and retrieve information using\nhyperdimensional computing - brain-inspired computing with 10,000-dimensional\nvectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from holovec import VSA\n\nprint(\"=\" * 70)\nprint(\"HoloVec Quickstart - Hyperdimensional Computing in 5 Minutes\")\nprint(\"=\" * 70)\nprint()\n\n# ============================================================================\n# Step 1: Create a VSA Model\n# ============================================================================\nprint(\"Step 1: Creating a VSA model\")\nprint(\"-\" * 70)\n\n# Create a FHRR model (Fourier Holographic Reduced Representations)\n# FHRR provides exact inverses and works well with continuous encoders\nmodel = VSA.create('FHRR', dim=10000, seed=42)\n\nprint(f\"Model: {model.model_name}\")\nprint(f\"Dimension: {model.dimension}\")\nprint(f\"Backend: {model.backend.name}\")\nprint()\n\n# ============================================================================\n# Step 2: Encode Symbolic Data\n# ============================================================================\nprint(\"Step 2: Encoding symbolic data\")\nprint(\"-\" * 70)\n\n# Create random hypervectors for symbols\n# Each symbol gets a unique 10,000-dimensional vector\nalice = model.random(seed=1)\nbob = model.random(seed=2)\nloves = model.random(seed=3)\nhates = model.random(seed=4)\n\nprint(\"Encoded symbols:\")\nprint(f\"  alice \u2192 10000-dim hypervector\")\nprint(f\"  bob   \u2192 10000-dim hypervector\")\nprint(f\"  loves \u2192 10000-dim hypervector\")\nprint(f\"  hates \u2192 10000-dim hypervector\")\nprint()\n\n# ============================================================================\n# Step 3: Compose Representations with Binding\n# ============================================================================\nprint(\"Step 3: Composing structured representations\")\nprint(\"-\" * 70)\n\n# Bind vectors to create structured representations\n# Binding creates a new vector that is dissimilar to both operands\nalice_loves_bob = model.bind(model.bind(alice, loves), bob)\nalice_hates_bob = model.bind(model.bind(alice, hates), bob)\n\nprint(\"Created compositional structures:\")\nprint(f\"  'Alice loves Bob' \u2192 single hypervector\")\nprint(f\"  'Alice hates Bob' \u2192 single hypervector\")\nprint()\n\n# These two statements are completely different\nsimilarity = model.similarity(alice_loves_bob, alice_hates_bob)\nprint(f\"Similarity between statements: {similarity:.3f}\")\nprint(\"  (Low similarity confirms they represent different facts)\")\nprint()\n\n# ============================================================================\n# Step 4: Query and Retrieve Information\n# ============================================================================\nprint(\"Step 4: Querying compositional structures\")\nprint(\"-\" * 70)\n\n# Query: Who does Alice love?\n# Unbind 'alice' and 'loves' from 'alice_loves_bob'\nquery_result = model.unbind(model.unbind(alice_loves_bob, alice), loves)\n\n# Check similarity to answer\nsimilarity_bob = model.similarity(query_result, bob)\nsimilarity_alice = model.similarity(query_result, alice)\n\nprint(\"Query: Who does Alice love?\")\nprint(f\"  Similarity to 'bob':   {similarity_bob:.3f}  \u2190 Answer!\")\nprint(f\"  Similarity to 'alice': {similarity_alice:.3f}\")\nprint()\n\n# ============================================================================\n# Step 5: Encode Continuous Values\n# ============================================================================\nprint(\"Step 5: Encoding continuous values\")\nprint(\"-\" * 70)\n\nfrom holovec.encoders import FractionalPowerEncoder\n\n# Create an encoder for temperatures (0-100\u00b0C)\ntemp_encoder = FractionalPowerEncoder(model, min_val=0, max_val=100, bandwidth=0.1)\n\n# Encode temperatures\ntemp_25 = temp_encoder.encode(25.0)\ntemp_26 = temp_encoder.encode(26.0)\ntemp_50 = temp_encoder.encode(50.0)\n\nprint(\"Encoded temperatures:\")\nprint(f\"  25\u00b0C \u2192 hypervector\")\nprint(f\"  26\u00b0C \u2192 hypervector\")\nprint(f\"  50\u00b0C \u2192 hypervector\")\nprint()\n\n# Similar values have high similarity\nsim_25_26 = model.similarity(temp_25, temp_26)\nsim_25_50 = model.similarity(temp_25, temp_50)\n\nprint(f\"Similarity (25\u00b0C, 26\u00b0C): {sim_25_26:.3f}  \u2190 Close values, high similarity\")\nprint(f\"Similarity (25\u00b0C, 50\u00b0C): {sim_25_50:.3f}  \u2190 Distant values, low similarity\")\nprint()\n\n# ============================================================================\n# Step 6: Build Associative Memory\n# ============================================================================\nprint(\"Step 6: Building associative memory\")\nprint(\"-\" * 70)\n\n# Create a simple associative memory\n# Bind objects to their properties\nhot = model.random(seed=10)\ncold = model.random(seed=11)\n\nfire_is_hot = model.bind(model.random(seed=20), hot)  # fire \u2192 hot\nice_is_cold = model.bind(model.random(seed=21), cold)  # ice \u2192 cold\n\n# Bundle related facts into knowledge base\nknowledge = model.bundle([fire_is_hot, ice_is_cold])\n\nprint(\"Created knowledge base:\")\nprint(f\"  'fire is hot' + 'ice is cold' \u2192 single hypervector\")\nprint()\n\n# Query: What is fire?\nfire = model.random(seed=20)\nfire_property = model.unbind(knowledge, fire)\n\nsim_hot = model.similarity(fire_property, hot)\nsim_cold = model.similarity(fire_property, cold)\n\nprint(\"Query: What property does fire have?\")\nprint(f\"  Similarity to 'hot':  {sim_hot:.3f}  \u2190 Answer!\")\nprint(f\"  Similarity to 'cold': {sim_cold:.3f}\")\nprint()\n\n# ============================================================================\n# Summary\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Summary: What You've Learned\")\nprint(\"=\" * 70)\nprint()\nprint(\"\u2713 Created a 10,000-dimensional VSA model\")\nprint(\"\u2713 Encoded symbolic data as hypervectors\")\nprint(\"\u2713 Composed structured representations with binding\")\nprint(\"\u2713 Retrieved information through unbinding\")\nprint(\"\u2713 Encoded continuous values with similarity preservation\")\nprint(\"\u2713 Built a simple associative memory\")\nprint()\nprint(\"Next steps:\")\nprint(\"  \u2192 01_basic_operations.py - Deep dive into VSA operations\")\nprint(\"  \u2192 02_models_comparison.py - Compare different VSA models\")\nprint(\"  \u2192 10_encoders_scalar.py - Master continuous value encoding\")\nprint()\nprint(\"Full documentation: https://docs.holovecai.com\")\nprint(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}