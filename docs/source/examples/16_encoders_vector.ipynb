{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multivariate Vector Encoding\n\nTopics: VectorEncoder, scalar encoder composition, high-dimensional data\nTime: 15 minutes\nPrerequisites: 00_quickstart.py, 10_encoders_scalar.py\nRelated: 17_encoders_image.py, 21_app_image_recognition.py\n\nThis example demonstrates the VectorEncoder, which encodes multivariate vectors\nby binding each dimension with its scalar value. This creates distributed\nrepresentations that preserve similarity between vectors with similar values.\n\nKey concepts:\n- Dimension binding: bind(dim_i, scalar_encode(value_i))\n- Scalar composition: works with any scalar encoder (FPE, Thermometer, Level)\n- High-dimensional: scales to 64D, 784D, or higher\n- Reversible: can decode to approximate original values\n\nThe VectorEncoder is fundamental for feature vectors, embeddings, sensor data,\nand flattened images (MNIST-style pixel arrays).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom holovec import VSA\nfrom holovec.encoders import (\n    VectorEncoder,\n    FractionalPowerEncoder,\n    ThermometerEncoder,\n    LevelEncoder,\n)\n\nprint(\"=\" * 70)\nprint(\"Multivariate Vector Encoding\")\nprint(\"=\" * 70)\nprint()\n\n# ============================================================================\n# Demo 1: Basic VectorEncoder Usage\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Demo 1: Basic VectorEncoder Usage\")\nprint(\"=\" * 70)\n\n# Create model and scalar encoder\nmodel = VSA.create('FHRR', dim=5000, seed=42)\nscalar_enc = FractionalPowerEncoder(model, min_val=0, max_val=10, seed=42)\n\n# Create vector encoder for 5D vectors\nencoder = VectorEncoder(\n    model,\n    scalar_encoder=scalar_enc,\n    n_dimensions=5,\n    seed=42\n)\n\nprint(f\"\\nEncoder: {encoder}\")\nprint(f\"Reversible: {encoder.is_reversible}\")\nprint(f\"Input type: {encoder.input_type}\")\n\n# Encode some vectors\nvectors = {\n    \"v1\": np.array([1.0, 2.0, 3.0, 4.0, 5.0]),\n    \"v2\": np.array([1.1, 2.1, 3.1, 4.1, 5.1]),  # Close to v1\n    \"v3\": np.array([5.0, 4.0, 3.0, 2.0, 1.0]),  # Reversed\n    \"v4\": np.array([8.0, 9.0, 7.0, 6.0, 10.0]), # Different\n}\n\nprint(\"\\nEncoding vectors:\")\nencoded = {}\nfor name, vec in vectors.items():\n    hv = encoder.encode(vec)\n    encoded[name] = hv\n    print(f\"  {name}: {vec} \u2192 HV shape: {hv.shape}\")\n\n# Similarity matrix\nprint(\"\\nSimilarity Matrix:\")\nnames = list(vectors.keys())\nprint(\"     \", \"  \".join(f\"{n:>6}\" for n in names))\nfor i, name1 in enumerate(names):\n    similarities = [\n        float(model.similarity(encoded[name1], encoded[name2]))\n        for name2 in names\n    ]\n    print(f\"{name1:>4}\", \"  \".join(f\"{s:6.3f}\" for s in similarities))\n\n# Test decoding\nprint(\"\\nDecoding test:\")\nfor name in ['v1', 'v2']:\n    original = vectors[name]\n    decoded = encoder.decode(encoded[name])\n    error = np.abs(original - decoded)\n    print(f\"\\n  {name} (original): {original}\")\n    print(f\"  {name} (decoded):  {decoded}\")\n    print(f\"  Error:            {error}\")\n    print(f\"  Max error:        {np.max(error):.3f}\")\n\nprint(\"\\nKey observations:\")\nprint(\"  - Similar vectors have high similarity\")\nprint(\"  - Different vectors are distinguishable\")\nprint(\"  - Decoding recovers approximate values\")\n\n# ============================================================================\n# Demo 2: Scalar Encoder Composition\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Demo 2: Scalar Encoder Composition\")\nprint(\"=\" * 70)\n\n# Test vector\ntest_vector = np.array([2.5, 5.0, 7.5])\n\n# Create encoders with different scalar encoders\nencoders = {\n    \"FractionalPower\": VectorEncoder(\n        model,\n        FractionalPowerEncoder(model, 0, 10, seed=42),\n        n_dimensions=3,\n        seed=42\n    ),\n    \"Thermometer\": VectorEncoder(\n        model,\n        ThermometerEncoder(model, 0, 10, n_bins=20),\n        n_dimensions=3,\n        seed=42\n    ),\n    \"Level\": VectorEncoder(\n        model,\n        LevelEncoder(model, 0, 10, n_levels=11),\n        n_dimensions=3,\n        seed=42\n    ),\n}\n\nprint(f\"\\nTest vector: {test_vector}\")\nprint(\"\\nScalar Encoder      | Reversible | HV Shape    | Can Decode\")\nprint(\"-\" * 65)\n\nencoded_comp = {}\nfor name, enc in encoders.items():\n    hv = enc.encode(test_vector)\n    encoded_comp[name] = hv\n    reversible = \"Yes\" if enc.is_reversible else \"No \"\n    can_decode = \"Yes\" if enc.is_reversible else \"No \"\n    print(f\"{name:18} | {reversible:>10} | {hv.shape} | {can_decode}\")\n\n# Compare similarities\nprint(\"\\nCross-encoder similarities:\")\nnames = list(encoders.keys())\nprint(\"                   \", \"  \".join(f\"{n:>15}\" for n in names))\nfor i, name1 in enumerate(names):\n    similarities = [\n        float(model.similarity(encoded_comp[name1], encoded_comp[name2]))\n        for name2 in names\n    ]\n    print(f\"{name1:18}\", \"  \".join(f\"{s:15.3f}\" for s in similarities))\n\n# Decode where possible\nprint(\"\\nDecoding (where supported):\")\nfor name, enc in encoders.items():\n    if enc.is_reversible:\n        decoded = enc.decode(encoded_comp[name])\n        error = np.abs(test_vector - decoded)\n        print(f\"\\n  {name}:\")\n        print(f\"    Original: {test_vector}\")\n        print(f\"    Decoded:  {decoded}\")\n        print(f\"    Max err:  {np.max(error):.3f}\")\n    else:\n        print(f\"\\n  {name}: Not reversible (skipped)\")\n\nprint(\"\\nKey observations:\")\nprint(\"  - VectorEncoder works with any scalar encoder\")\nprint(\"  - Different scalar encoders give different properties\")\nprint(\"  - Composition enables flexible encoding strategies\")\n\n# ============================================================================\n# Demo 3: High-Dimensional Data (MNIST-style Images)\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Demo 3: High-Dimensional Data (MNIST-style)\")\nprint(\"=\" * 70)\n\n# Simulate small grayscale images (8x8 like mini-MNIST)\nmodel_hd = VSA.create('FHRR', dim=10000, seed=42)\n\n# Create encoder for 64-dimensional vectors (8x8 images)\nscalar_enc_hd = FractionalPowerEncoder(model_hd, min_val=0, max_val=255, seed=42)\nencoder_hd = VectorEncoder(\n    model_hd,\n    scalar_encoder=scalar_enc_hd,\n    n_dimensions=64,  # 8x8 flattened\n    normalize_input=False,\n    seed=42\n)\n\nprint(f\"\\nEncoder: {encoder_hd}\")\nprint(f\"Image size: 8x8 = 64 pixels\")\nprint(f\"Pixel range: 0-255 (grayscale)\")\n\n# Create synthetic \"images\"\nnp.random.seed(42)\nimages = {\n    \"digit_1\": np.random.randint(0, 50, 64),    # Dark image\n    \"digit_1b\": np.random.randint(0, 50, 64) + np.random.randint(-5, 5, 64),  # Similar\n    \"digit_7\": np.random.randint(100, 255, 64),  # Bright image\n    \"noise\": np.random.randint(0, 255, 64),      # Random\n}\n\nprint(\"\\nEncoding images:\")\nencoded_imgs = {}\nfor name, img in images.items():\n    hv = encoder_hd.encode(img.astype(float))\n    encoded_imgs[name] = hv\n    print(f\"  {name:10s}: mean={np.mean(img):6.1f}, std={np.std(img):5.1f} \"\n          f\"\u2192 HV shape: {hv.shape}\")\n\n# Similarity matrix\nprint(\"\\nSimilarity Matrix:\")\nnames = list(images.keys())\nprint(\"           \", \"  \".join(f\"{n:>10}\" for n in names))\nfor i, name1 in enumerate(names):\n    similarities = [\n        float(model_hd.similarity(encoded_imgs[name1], encoded_imgs[name2]))\n        for name2 in names\n    ]\n    print(f\"{name1:10}\", \"  \".join(f\"{s:10.3f}\" for s in similarities))\n\n# Test reconstruction\nprint(\"\\nReconstruction test (first image):\")\noriginal = images[\"digit_1\"].astype(float)\ndecoded = encoder_hd.decode(encoded_imgs[\"digit_1\"])\n\n# Reshape for display (8x8)\norig_grid = original.reshape(8, 8)\ndec_grid = decoded.reshape(8, 8)\n\nprint(\"\\nOriginal image (8x8):\")\nprint(orig_grid.astype(int))\n\nprint(\"\\nDecoded image (8x8):\")\nprint(dec_grid.astype(int))\n\nrmse = np.sqrt(np.mean((original - decoded) ** 2))\nprint(f\"\\nReconstruction RMSE: {rmse:.2f}\")\nprint(f\"Pixel correlation: {np.corrcoef(original, decoded)[0, 1]:.3f}\")\n\nprint(\"\\nKey observations:\")\nprint(\"  - VectorEncoder scales to high-dimensional data (64D, 784D, etc.)\")\nprint(\"  - Similar images have higher similarity\")\nprint(\"  - Approximate reconstruction preserves main features\")\nprint(\"  - Ready for classification via similarity search\")\n\n# ============================================================================\n# Summary\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Summary: VectorEncoder Key Takeaways\")\nprint(\"=\" * 70)\nprint()\nprint(\"\u2713 Multivariate: Encodes vectors by binding dimensions with values\")\nprint(\"\u2713 Compositional: Works with any scalar encoder (FPE, Thermometer, Level)\")\nprint(\"\u2713 Scalable: Handles 5D, 64D, 784D, or higher dimensions\")\nprint(\"\u2713 Reversible: Decodes to approximate original values (with FPE)\")\nprint(\"\u2713 Similarity-preserving: Similar vectors \u2192 similar hypervectors\")\nprint()\nprint(\"Use cases:\")\nprint(\"  - Feature vectors: ML model outputs, embeddings\")\nprint(\"  - Sensor data: Multiple sensors, time steps\")\nprint(\"  - Flattened images: MNIST (784D), CIFAR (3072D)\")\nprint(\"  - Scientific data: Multivariate measurements\")\nprint()\nprint(\"Next steps:\")\nprint(\"  \u2192 17_encoders_image.py - 2D spatial structure encoding\")\nprint(\"  \u2192 21_app_image_recognition.py - Apply to real image data\")\nprint(\"  \u2192 25_app_integration_patterns.py - Combine with other encoders\")\nprint()\nprint(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}