{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Image Pattern Recognition\n\nTopics: Image classification, spatial encoding, pattern matching, computer vision\nTime: 15 minutes\nPrerequisites: 17_encoders_image.py, 16_encoders_vector.py\nRelated: 20_app_text_classification.py, 25_app_integration_patterns.py\n\nThis example demonstrates practical image pattern recognition using\nhyperdimensional computing. Learn how to classify simple image patterns\nusing spatial encoding techniques.\n\nKey concepts:\n- Image encoding: Flatten pixels + VectorEncoder\n- Pattern prototypes: Bundle examples per class\n- Classification: Similarity-based matching\n- Practical considerations: Real-world trade-offs\n\nImage recognition with HDC is efficient and works well for simple patterns,\nedge devices, and situations with limited training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom holovec import VSA\nfrom holovec.encoders import VectorEncoder, FractionalPowerEncoder\nfrom holovec.retrieval import ItemStore\n\nprint(\"=\" * 70)\nprint(\"Image Pattern Recognition\")\nprint(\"=\" * 70)\nprint()\n\n# Create model and encoder\nmodel = VSA.create('FHRR', dim=10000, seed=42)\n\n# For 8x8 images (64 pixels)\nscalar_encoder = FractionalPowerEncoder(model, min_val=0, max_val=255, seed=42)\nimage_encoder = VectorEncoder(model, scalar_encoder, n_dimensions=64, seed=43)\n\nprint(f\"Model: {model.model_name}, dimension={model.dimension}\")\nprint(f\"Image encoder: 8x8 grayscale (64D flattened)\")\nprint()\n\n# ============================================================================\n# Dataset: Simple Shape Patterns\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Dataset: Simple 8x8 Shapes\")\nprint(\"=\" * 70)\n\nnp.random.seed(42)\n\n# Create simple synthetic patterns\ndef create_vertical_line():\n    \"\"\"Vertical line pattern.\"\"\"\n    img = np.zeros((8, 8), dtype=np.uint8)\n    img[:, 3:5] = 200  # Vertical line in middle\n    return img.flatten()\n\ndef create_horizontal_line():\n    \"\"\"Horizontal line pattern.\"\"\"\n    img = np.zeros((8, 8), dtype=np.uint8)\n    img[3:5, :] = 200  # Horizontal line in middle\n    return img.flatten()\n\ndef create_cross():\n    \"\"\"Cross pattern.\"\"\"\n    img = np.zeros((8, 8), dtype=np.uint8)\n    img[3:5, :] = 200  # Horizontal\n    img[:, 3:5] = 200  # Vertical\n    return img.flatten()\n\ndef create_square():\n    \"\"\"Square pattern.\"\"\"\n    img = np.zeros((8, 8), dtype=np.uint8)\n    img[2:6, 2:6] = 200  # Square\n    return img.flatten()\n\n# Generate training examples with variations (noise)\nprint(\"\\nGenerating training examples (4 classes, 5 examples each):\")\n\ntraining_data = []\nnoise_level = 15  # pixel noise\n\n# Vertical lines\nfor i in range(5):\n    img = create_vertical_line() + np.random.randint(-noise_level, noise_level, 64)\n    img = np.clip(img, 0, 255)\n    training_data.append((img, \"vertical\"))\n\n# Horizontal lines\nfor i in range(5):\n    img = create_horizontal_line() + np.random.randint(-noise_level, noise_level, 64)\n    img = np.clip(img, 0, 255)\n    training_data.append((img, \"horizontal\"))\n\n# Crosses\nfor i in range(5):\n    img = create_cross() + np.random.randint(-noise_level, noise_level, 64)\n    img = np.clip(img, 0, 255)\n    training_data.append((img, \"cross\"))\n\n# Squares\nfor i in range(5):\n    img = create_square() + np.random.randint(-noise_level, noise_level, 64)\n    img = np.clip(img, 0, 255)\n    training_data.append((img, \"square\"))\n\nprint(f\"  vertical:   5 examples\")\nprint(f\"  horizontal: 5 examples\")\nprint(f\"  cross:      5 examples\")\nprint(f\"  square:     5 examples\")\nprint(f\"\\nTotal: {len(training_data)} training examples\")\n\n# ============================================================================\n# Training: Build Pattern Prototypes\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Training: Building Pattern Prototypes\")\nprint(\"=\" * 70)\n\n# Group by class\nclasses = {}\nfor img, label in training_data:\n    if label not in classes:\n        classes[label] = []\n    classes[label].append(img)\n\n# Encode and bundle per class\npattern_prototypes = {}\n\nprint(\"\\nEncoding patterns:\")\nfor label, images in classes.items():\n    encoded = [image_encoder.encode(img.astype(float)) for img in images]\n    prototype = model.bundle(encoded)\n    pattern_prototypes[label] = prototype\n    print(f\"  {label:12s}: {len(images)} examples \u2192 prototype\")\n\nprint(f\"\\nPattern prototypes created: {len(pattern_prototypes)}\")\n\n# ============================================================================\n# Classification: Test on New Patterns\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Classification: Testing on New Patterns\")\nprint(\"=\" * 70)\n\n# Create test patterns with noise\ntest_patterns = [\n    (create_vertical_line() + np.random.randint(-10, 10, 64), \"vertical\"),\n    (create_horizontal_line() + np.random.randint(-10, 10, 64), \"horizontal\"),\n    (create_cross() + np.random.randint(-10, 10, 64), \"cross\"),\n    (create_square() + np.random.randint(-10, 10, 64), \"square\"),\n]\n\ntest_patterns = [(np.clip(img, 0, 255), label) for img, label in test_patterns]\n\nprint(\"\\nClassifying test patterns:\")\nprint()\n\ncorrect = 0\nfor i, (img, expected) in enumerate(test_patterns, 1):\n    # Encode test pattern\n    test_hv = image_encoder.encode(img.astype(float))\n\n    # Find most similar prototype\n    best_label = None\n    best_sim = float('-inf')\n\n    for label, prototype in pattern_prototypes.items():\n        sim = float(model.similarity(test_hv, prototype))\n        if sim > best_sim:\n            best_sim = sim\n            best_label = label\n\n    is_correct = (best_label == expected)\n    correct += (1 if is_correct else 0)\n    marker = \"\u2713\" if is_correct else \"\u2717\"\n\n    print(f\"{i}. Pattern: {expected:12s}\")\n    print(f\"   Predicted: {best_label:12s} (similarity={best_sim:.3f}) {marker}\")\n    print()\n\naccuracy = correct / len(test_patterns)\nprint(f\"Accuracy: {correct}/{len(test_patterns)} = {accuracy:.1%}\")\n\n# ============================================================================\n# Analysis: Similarity Scores\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Analysis: Pattern Similarity Matrix\")\nprint(\"=\" * 70)\n\nprint(\"\\nSimilarity between pattern prototypes:\")\nlabels = sorted(pattern_prototypes.keys())\n\n# Print header\nprint(f\"{'':12s}\", end=\"\")\nfor label in labels:\n    print(f\" {label:>10s}\", end=\"\")\nprint()\n\n# Print matrix\nfor label1 in labels:\n    print(f\"{label1:12s}\", end=\"\")\n    for label2 in labels:\n        sim = float(model.similarity(pattern_prototypes[label1],\n                                      pattern_prototypes[label2]))\n        print(f\" {sim:10.3f}\", end=\"\")\n    print()\n\nprint(\"\\nKey observation:\")\nprint(\"  - Diagonal = 1.0 (self-similarity)\")\nprint(\"  - Off-diagonal shows inter-class confusion\")\nprint(\"  - Cross similar to both vertical and horizontal\")\n\n# ============================================================================\n# Practical Considerations\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Practical Considerations\")\nprint(\"=\" * 70)\n\nprint(\"\\n\u2713 Advantages of HDC Image Recognition:\")\nprint(\"  - Fast: No backpropagation or gradient descent\")\nprint(\"  - Small: Works with limited training data\")\nprint(\"  - Efficient: Low memory and compute requirements\")\nprint(\"  - Interpretable: Similarity scores show confidence\")\nprint(\"  - Robust: Tolerant to noise and distortions\")\nprint()\n\nprint(\"\u2717 Limitations:\")\nprint(\"  - Accuracy: Not as good as CNNs for complex images\")\nprint(\"  - Scale: Best for small images (8x8, 16x16, 28x28)\")\nprint(\"  - Features: Doesn't learn features like deep learning\")\nprint(\"  - Flattening: Loses 2D spatial structure\")\nprint()\n\nprint(\"Best use cases:\")\nprint(\"  - Edge devices (limited compute/memory)\")\nprint(\"  - Few-shot learning (< 10 examples per class)\")\nprint(\"  - Simple patterns (icons, symbols, digits)\")\nprint(\"  - Rapid prototyping (baseline before CNN)\")\nprint(\"  - Explainable AI (similarity scores)\")\nprint()\n\n# ============================================================================\n# Extension: Efficient Multi-Pattern Recognition\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Extension: ItemStore for Efficient Recognition\")\nprint(\"=\" * 70)\n\n# Build pattern store\npattern_store = ItemStore(model)\nfor label, prototype in pattern_prototypes.items():\n    pattern_store.add(label, prototype)\n\nprint(f\"\\nPattern store built with {len(pattern_prototypes)} classes\")\n\n# Test pattern\ntest_img = create_cross() + np.random.randint(-15, 15, 64)\ntest_img = np.clip(test_img, 0, 255)\ntest_hv = image_encoder.encode(test_img.astype(float))\n\n# Query returns ranked results\nresults = pattern_store.query(test_hv, k=4)\n\nprint(\"\\nTest pattern: cross (with noise)\")\nprint(\"\\nTop predictions:\")\nfor i, (label, sim) in enumerate(results, 1):\n    print(f\"  {i}. {label:12s}: {sim:.3f}\")\n\nprint(\"\\nKey observation:\")\nprint(\"  - ItemStore enables fast k-nearest pattern retrieval\")\nprint(\"  - Can examine confidence of predictions\")\nprint(\"  - Scales to many pattern classes\")\n\n# ============================================================================\n# Summary\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Summary: Image Pattern Recognition with HDC\")\nprint(\"=\" * 70)\nprint()\nprint(\"Complete workflow:\")\nprint(\"  1. Setup: Create model + VectorEncoder for flattened pixels\")\nprint(\"  2. Training: Encode images + bundle per pattern class\")\nprint(\"  3. Recognition: Encode test image + find nearest prototype\")\nprint(\"  4. Evaluation: Check similarity for confidence\")\nprint()\nprint(\"Performance tips:\")\nprint(\"  - Use FractionalPowerEncoder for pixel values (continuous)\")\nprint(\"  - Normalize images to [0, 1] or [0, 255]\")\nprint(\"  - More training examples \u2192 better prototypes\")\nprint(\"  - Consider ImageEncoder (17) for true 2D spatial structure\")\nprint()\nprint(\"Next steps:\")\nprint(\"  \u2192 Try with MNIST digits (28x28 = 784D)\")\nprint(\"  \u2192 Experiment with different scalar encoders\")\nprint(\"  \u2192 Use ImageEncoder (17) for full spatial encoding\")\nprint(\"  \u2192 Combine with 25_app_integration_patterns.py for multimodal\")\nprint()\nprint(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}