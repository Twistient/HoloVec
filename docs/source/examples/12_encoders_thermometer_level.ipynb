{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Thermometer and Level Encoders Deep Dive\n\nTopics: Ordinal encoding, discrete bins, model compatibility, use cases\nTime: 10 minutes\nPrerequisites: 10_encoders_scalar.py, 01_basic_operations.py\nRelated: 11_encoders_fractional_power.py, 02_models_comparison.py\n\nThis example explores ThermometerEncoder and LevelEncoder - the universal\nscalar encoders that work with all VSA models (MAP, BSC, FHRR, HRR, etc).\n\nKey concepts:\n- Thermometer encoding: Cumulative activation (ordinal relationships)\n- Level encoding: One-hot bins (categorical values)\n- Model compatibility: Works with ALL VSA models\n- Trade-offs: Discrete vs smooth similarity\n- Use cases: Rankings, categories, MAP/BSC applications\n\nUse these encoders when you need model-agnostic encoding or when working\nwith MAP, BSC, or BSDC models (which don't support FPE).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom holovec import VSA\nfrom holovec.encoders import ThermometerEncoder, LevelEncoder\n\nprint(\"=\" * 70)\nprint(\"Thermometer and Level Encoders Deep Dive\")\nprint(\"=\" * 70)\nprint()\n\n# ============================================================================\n# Demo 1: Thermometer Encoder - Ordinal Relationships\n# ============================================================================\nprint(\"=\" * 70)\nprint(\"Demo 1: ThermometerEncoder - Ordinal Encoding\")\nprint(\"=\" * 70)\n\nmodel = VSA.create('MAP', dim=10000, seed=42)\n\n# Create thermometer encoder with different bin counts\nn_bins_options = [10, 20, 50, 100]\n\nprint(f\"\\nModel: {model.model_name}, dimension={model.dimension}\")\nprint(f\"Range: 0-100\")\nprint()\n\n# Test similarity with different bin counts\ntest_pairs = [(50, 51), (50, 55), (50, 60), (50, 75)]\n\nprint(f\"{'Bins':<8s} \", end=\"\")\nfor v1, v2 in test_pairs:\n    print(f\"{v1}-{v2:<5d} \", end=\"\")\nprint()\nprint(\"-\" * 50)\n\nfor n_bins in n_bins_options:\n    encoder = ThermometerEncoder(model, min_val=0, max_val=100, n_bins=n_bins)\n    print(f\"{n_bins:<8d} \", end=\"\")\n\n    for v1, v2 in test_pairs:\n        hv1 = encoder.encode(v1)\n        hv2 = encoder.encode(v2)\n        sim = float(model.similarity(hv1, hv2))\n        print(f\"{sim:7.3f} \", end=\"\")\n    print()\n\nprint(\"\\nObservations:\")\nprint(\"  - More bins = finer granularity, lower similarity for same distance\")\nprint(\"  - Fewer bins = coarser, higher similarity, more grouping\")\nprint(\"  - Ordinal property: similarity decreases monotonically with distance\")\n\n# ============================================================================\n# Demo 2: Thermometer Properties\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Demo 2: Thermometer Encoding Properties\")\nprint(\"=\" * 70)\n\nencoder = ThermometerEncoder(model, min_val=0, max_val=100, n_bins=20)\n\nprint(f\"\\nBin size: {(100 / 20):.1f} units per bin\")\nprint(f\"Reversible: {encoder.is_reversible}\")\nprint(f\"Compatible models: {encoder.compatible_models}\")\nprint()\n\n# Show ordinal property\nvalues = [10, 30, 50, 70, 90]\nreference = 50\n\nprint(f\"Reference value: {reference}\")\nprint(f\"\\n{'Value':<10s} {'Distance':<10s} {'Similarity':<12s}\")\nprint(\"-\" * 40)\n\nfor val in values:\n    hv_ref = encoder.encode(reference)\n    hv_val = encoder.encode(val)\n    sim = float(model.similarity(hv_ref, hv_val))\n    dist = abs(val - reference)\n    print(f\"{val:<10.1f} {dist:<10.1f} {sim:8.3f}\")\n\nprint(\"\\nKey property:\")\nprint(\"  - Monotonic: similarity decreases as distance increases\")\nprint(\"  - Symmetric: sim(A,B) = sim(B,A)\")\nprint(\"  - Cumulative: each value activates bins 0..n\")\n\n# ============================================================================\n# Demo 3: Level Encoder - Discrete Categories\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Demo 3: LevelEncoder - Discrete Bins\")\nprint(\"=\" * 70)\n\n# Create level encoder\nlevel_encoder = LevelEncoder(model, min_val=0, max_val=100, n_levels=5)\n\nprint(f\"\\nLevels: {level_encoder.n_levels}\")\nprint(f\"Bin size: {100 / 5:.1f} units per level\")\nprint(f\"Reversible: {level_encoder.is_reversible}\")\nprint()\n\n# Map values to levels\ntest_values = [5, 15, 35, 55, 75, 95]\n\nprint(f\"{'Value':<10s} {'Level':<10s} {'Decoded':<10s}\")\nprint(\"-\" * 35)\n\nfor val in test_values:\n    hv = level_encoder.encode(val)\n    decoded = level_encoder.decode(hv)\n    print(f\"{val:<10.1f} {int(val // 20):<10d} {decoded:<10.1f}\")\n\nprint(\"\\nLevel bins:\")\nprint(\"  [0-20)   \u2192 Level 0 \u2192 decoded as 10.0\")\nprint(\"  [20-40)  \u2192 Level 1 \u2192 decoded as 30.0\")\nprint(\"  [40-60)  \u2192 Level 2 \u2192 decoded as 50.0\")\nprint(\"  [60-80)  \u2192 Level 3 \u2192 decoded as 70.0\")\nprint(\"  [80-100] \u2192 Level 4 \u2192 decoded as 90.0\")\n\n# ============================================================================\n# Demo 4: Level vs Thermometer Comparison\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Demo 4: Level vs Thermometer Similarity Patterns\")\nprint(\"=\" * 70)\n\nthermo = ThermometerEncoder(model, min_val=0, max_val=100, n_bins=20)\nlevel = LevelEncoder(model, min_val=0, max_val=100, n_levels=5)\n\nreference = 50.0\ntest_vals = np.linspace(0, 100, 11)\n\nprint(f\"\\nReference: {reference}\")\nprint(f\"\\n{'Value':<10s} {'Thermo Sim':<12s} {'Level Sim':<12s}\")\nprint(\"-\" * 40)\n\nfor val in test_vals:\n    # Thermometer\n    ref_t = thermo.encode(reference)\n    val_t = thermo.encode(val)\n    sim_t = float(model.similarity(ref_t, val_t))\n\n    # Level\n    ref_l = level.encode(reference)\n    val_l = level.encode(val)\n    sim_l = float(model.similarity(ref_l, val_l))\n\n    print(f\"{val:<10.1f} {sim_t:8.3f}     {sim_l:8.3f}\")\n\nprint(\"\\nKey differences:\")\nprint(\"  Thermometer: Gradual similarity decay\")\nprint(\"  Level:       High similarity within bin, drop across bins\")\n\n# ============================================================================\n# Demo 5: Model Compatibility\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Demo 5: Universal Model Compatibility\")\nprint(\"=\" * 70)\n\ntest_value = 42.5\n\nprint(\"\\n\u2713 Thermometer and Level work with ALL models:\\n\")\n\nfor model_name in ['MAP', 'FHRR', 'HRR', 'BSC']:\n    m = VSA.create(model_name, dim=5000, seed=42)\n\n    # Thermometer\n    thermo = ThermometerEncoder(m, min_val=0, max_val=100, n_bins=20)\n    hv_t = thermo.encode(test_value)\n\n    # Level\n    level = LevelEncoder(m, min_val=0, max_val=100, n_levels=10)\n    hv_l = level.encode(test_value)\n    decoded_l = level.decode(hv_l)\n\n    print(f\"{model_name:10s}: Thermometer \u2713  Level \u2713  (decoded={decoded_l:.1f})\")\n\nprint(\"\\nVersus FPE:\")\nprint(\"  FPE: Only FHRR, HRR (requires complex representation)\")\nprint(\"  Thermo/Level: ALL models (universal)\")\n\n# ============================================================================\n# Demo 6: Bin Count Selection\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Demo 6: Choosing Number of Bins/Levels\")\nprint(\"=\" * 70)\n\nprint(\"\\nRule of thumb:\")\nprint(\"  bins \u2248 dimension / 200  (for good orthogonality)\")\nprint()\n\ndimensions = [1000, 5000, 10000, 20000]\n\nprint(f\"{'Dimension':<12s} {'Suggested Bins':<15s} {'Reasoning'}\")\nprint(\"-\" * 60)\n\nfor dim in dimensions:\n    suggested = dim // 200\n    print(f\"{dim:<12d} {suggested:<15d} ~{suggested} orthogonal vectors available\")\n\nprint(\"\\nTrade-offs:\")\nprint(\"  More bins:   Finer resolution, needs higher dimension\")\nprint(\"  Fewer bins:  Coarser, works with lower dimension\")\n\n# Test capacity\ndim = 10000\nprint(f\"\\nCapacity test for dimension={dim}:\")\n\nfor n_bins in [10, 50, 100, 200]:\n    model = VSA.create('MAP', dim=dim, seed=42)\n    encoder = ThermometerEncoder(model, min_val=0, max_val=100, n_bins=n_bins)\n\n    # Create all bin vectors and check orthogonality\n    bin_hvs = [encoder.encode(i * (100 / n_bins)) for i in range(n_bins)]\n\n    # Average similarity between different bins\n    sims = []\n    for i in range(len(bin_hvs)):\n        for j in range(i+1, len(bin_hvs)):\n            sim = float(model.similarity(bin_hvs[i], bin_hvs[j]))\n            sims.append(abs(sim))\n\n    avg_cross_sim = np.mean(sims) if sims else 0\n\n    print(f\"  {n_bins:3d} bins: avg cross-similarity = {avg_cross_sim:.3f}\")\n\nprint(\"\\nTarget: cross-similarity < 0.1 for good separation\")\n\n# ============================================================================\n# Demo 7: Use Cases and Recommendations\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Demo 7: When to Use Each Encoder\")\nprint(\"=\" * 70)\n\nprint(\"\\n\u2713 Use ThermometerEncoder when:\")\nprint(\"  - Need ordinal relationships (rankings, scores)\")\nprint(\"  - Using MAP, BSC, or BSDC models\")\nprint(\"  - Want monotonic similarity decay\")\nprint(\"  - Don't need exact value recovery\")\nprint(\"  Examples: product ratings, priority levels, age groups\")\nprint()\n\nprint(\"\u2713 Use LevelEncoder when:\")\nprint(\"  - Have discrete categories or bins\")\nprint(\"  - Need reversible encoding with categorical output\")\nprint(\"  - Want sharp boundaries between levels\")\nprint(\"  - Using any VSA model\")\nprint(\"  Examples: grade levels (A/B/C), risk categories, size buckets\")\nprint()\n\nprint(\"\u2713 Use FractionalPowerEncoder when:\")\nprint(\"  - Need smooth similarity for continuous values\")\nprint(\"  - Using FHRR or HRR models\")\nprint(\"  - Want exact value recovery (reversible)\")\nprint(\"  - Have precise measurements\")\nprint(\"  Examples: temperature, pressure, time, GPS coordinates\")\n\n# ============================================================================\n# Demo 8: Practical Pattern - Rating System\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Demo 8: Practical Example - Product Rating System\")\nprint(\"=\" * 70)\n\nmodel = VSA.create('MAP', dim=10000, seed=42)\n\n# 5-star rating system with half stars (0.5 increments)\nrating_encoder = LevelEncoder(model, min_val=0.0, max_val=5.0, n_levels=10)\n\n# Sample products with ratings\nproducts = {\n    \"Laptop\": 4.5,\n    \"Mouse\": 3.5,\n    \"Keyboard\": 4.0,\n    \"Monitor\": 4.5,\n    \"Webcam\": 3.0\n}\n\n# Create product symbols\nproduct_hvs = {name: model.random(seed=hash(name) % 10000)\n               for name in products.keys()}\n\n# Bind product to rating\nRATING = model.random(seed=99)\nproduct_ratings = {}\n\nprint(\"\\nProduct ratings:\")\nfor name, rating in products.items():\n    rating_hv = rating_encoder.encode(rating)\n    product_rating = model.bind(product_hvs[name], model.bind(RATING, rating_hv))\n    product_ratings[name] = product_rating\n    print(f\"  {name:12s}: {rating:.1f} stars\")\n\n# Query: Find products with ~4.5 stars\ntarget_rating = 4.5\ntarget_hv = rating_encoder.encode(target_rating)\n\nprint(f\"\\nSearching for products rated ~{target_rating} stars:\")\nprint(f\"\\n{'Product':<12s} {'Actual':<10s} {'Similarity':<12s}\")\nprint(\"-\" * 40)\n\nfor name, rating in products.items():\n    rating_hv = rating_encoder.encode(rating)\n    sim = float(model.similarity(rating_hv, target_hv))\n    print(f\"{name:12s} {rating:.1f}        {sim:8.3f}\")\n\nprint(\"\\nHigh similarity products have similar ratings!\")\n\n# ============================================================================\n# Summary\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Summary: Thermometer vs Level vs FPE\")\nprint(\"=\" * 70)\nprint()\n\nsummary_table = \"\"\"\nFeature              Thermometer    Level          FPE\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nModel compatibility  ALL            ALL            FHRR,HRR only\nSimilarity type      Gradual decay  Sharp bins     Smooth decay\nReversible           No             Yes            Yes\nOrdinal property     Yes            Partial        Yes\nBest for            Rankings       Categories     Continuous\nBin granularity     Flexible       Flexible       Continuous\nValue recovery      No             Bin center     Exact\n\"\"\"\n\nprint(summary_table)\n\nprint(\"\\nQuick selection guide:\")\nprint(\"  1. Check model: MAP/BSC? \u2192 Use Thermometer or Level\")\nprint(\"  2. Need reversible? \u2192 Level (discrete) or FPE (smooth)\")\nprint(\"  3. Ordinal only? \u2192 Thermometer\")\nprint(\"  4. Continuous precision? \u2192 FPE (if using FHRR/HRR)\")\nprint()\n\nprint(\"Next steps:\")\nprint(\"  \u2192 11_encoders_fractional_power.py - FPE deep dive\")\nprint(\"  \u2192 02_models_comparison.py - Choose the right model\")\nprint(\"  \u2192 20_app_text_classification.py - Apply encoders in practice\")\nprint()\nprint(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}